{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Telecom Churn Case Study\n",
    "PG Diploma in Machine Learning and AI March 2018<br/>\n",
    "Group Members\n",
    "1. Reghuram Vasanthakumari\n",
    "2. Sanjoy Krishna Ghosh\n",
    "3. Dipesh Singhal\n",
    "4. Naveen Bharadwaj\n",
    "\n",
    "The analysis is divided into following parts<br/>\n",
    "1. Filter high-value customers<br/>\n",
    "2. Handlling The Missing Values<br/>\n",
    "3. Derive new features<br/>\n",
    "4. Splitting the Test and Train Data<br/>\n",
    "5. PCA\n",
    "6. Logistic Regression<br/>\n",
    "7. SVM<br/>\n",
    "8. XGBoost<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data understanding, preparation, and feature engineering  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('telecom_churn_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99999, 226)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_rech_data_6</th>\n",
       "      <th>total_rech_data_7</th>\n",
       "      <th>total_rech_data_8</th>\n",
       "      <th>total_rech_data_9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   total_rech_data_6  total_rech_data_7  total_rech_data_8  total_rech_data_9\n",
       "0                1.0                1.0                1.0                NaN\n",
       "1                NaN                1.0                2.0                NaN\n",
       "2                NaN                NaN                NaN                1.0\n",
       "3                NaN                NaN                NaN                NaN\n",
       "4                1.0                NaN                NaN                NaN"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(data.shape)\n",
    "#pd.set_option('display.max_columns', None)\n",
    "#pd.set_option('display.max_rows', None)\n",
    "# data.isnull().sum().sort_values()/data.shape[0]*100 > 73\n",
    "data.head(5)\n",
    "data.filter(like='total_rech_data').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#data.mobile_number.unique().size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#sample = data.head()\n",
    "#months_data = sample.filter(like='rech')\n",
    "#months_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Filter high-value customers\n",
    "filtering the high value custmer in data frame max_revenue_customers_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data['average_recharge']=(data.total_rech_amt_6+data.total_rech_amt_7)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count       99999.000000\n",
       "mean          325.238792\n",
       "std           370.833466\n",
       "min             0.000000\n",
       "50%           229.000000\n",
       "70%           368.500000\n",
       "90%           698.000000\n",
       "99%          1590.000000\n",
       "99.9%        3037.514000\n",
       "99.9999%    35861.288025\n",
       "max         37762.500000\n",
       "Name: average_recharge, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.average_recharge.describe(percentiles=[0.7,0.9,0.99,0.999,0.999999])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#70% is at 368.5 so filtering based on that\n",
    "max_revenue_customers_data = data[data.average_recharge >368.5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Handlling The Missing Values \n",
    "Finding how much missing value we have for each coloum and handle them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mobile_number            0.0\n",
       "circle_id                0.0\n",
       "loc_og_t2o_mou           1.0\n",
       "std_og_t2o_mou           1.0\n",
       "loc_ic_t2o_mou           1.0\n",
       "last_date_of_month_6     0.0\n",
       "last_date_of_month_7     1.0\n",
       "last_date_of_month_8     1.0\n",
       "last_date_of_month_9     2.0\n",
       "arpu_6                   0.0\n",
       "arpu_7                   0.0\n",
       "arpu_8                   0.0\n",
       "arpu_9                   0.0\n",
       "onnet_mou_6              4.0\n",
       "onnet_mou_7              4.0\n",
       "onnet_mou_8              5.0\n",
       "onnet_mou_9              8.0\n",
       "offnet_mou_6             4.0\n",
       "offnet_mou_7             4.0\n",
       "offnet_mou_8             5.0\n",
       "offnet_mou_9             8.0\n",
       "roam_ic_mou_6            4.0\n",
       "roam_ic_mou_7            4.0\n",
       "roam_ic_mou_8            5.0\n",
       "roam_ic_mou_9            8.0\n",
       "roam_og_mou_6            4.0\n",
       "roam_og_mou_7            4.0\n",
       "roam_og_mou_8            5.0\n",
       "roam_og_mou_9            8.0\n",
       "loc_og_t2t_mou_6         4.0\n",
       "                        ... \n",
       "night_pck_user_6        75.0\n",
       "night_pck_user_7        74.0\n",
       "night_pck_user_8        74.0\n",
       "night_pck_user_9        74.0\n",
       "monthly_2g_6             0.0\n",
       "monthly_2g_7             0.0\n",
       "monthly_2g_8             0.0\n",
       "monthly_2g_9             0.0\n",
       "sachet_2g_6              0.0\n",
       "sachet_2g_7              0.0\n",
       "sachet_2g_8              0.0\n",
       "sachet_2g_9              0.0\n",
       "monthly_3g_6             0.0\n",
       "monthly_3g_7             0.0\n",
       "monthly_3g_8             0.0\n",
       "monthly_3g_9             0.0\n",
       "sachet_3g_6              0.0\n",
       "sachet_3g_7              0.0\n",
       "sachet_3g_8              0.0\n",
       "sachet_3g_9              0.0\n",
       "fb_user_6               75.0\n",
       "fb_user_7               74.0\n",
       "fb_user_8               74.0\n",
       "fb_user_9               74.0\n",
       "aon                      0.0\n",
       "aug_vbc_3g               0.0\n",
       "jul_vbc_3g               0.0\n",
       "jun_vbc_3g               0.0\n",
       "sep_vbc_3g               0.0\n",
       "average_recharge         0.0\n",
       "Length: 227, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#missing value before any change\n",
    "round(data.isnull().sum()/len(data.index), 2)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#first find high missing value (above 60%) columns\n",
    "missing_columns = data.columns[100*(data.isnull().sum()/len(data.index)) > 60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date_of_last_rech_data_6', 'date_of_last_rech_data_7',\n",
       "       'date_of_last_rech_data_8', 'date_of_last_rech_data_9',\n",
       "       'total_rech_data_6', 'total_rech_data_7', 'total_rech_data_8',\n",
       "       'total_rech_data_9', 'max_rech_data_6', 'max_rech_data_7',\n",
       "       'max_rech_data_8', 'max_rech_data_9', 'count_rech_2g_6',\n",
       "       'count_rech_2g_7', 'count_rech_2g_8', 'count_rech_2g_9',\n",
       "       'count_rech_3g_6', 'count_rech_3g_7', 'count_rech_3g_8',\n",
       "       'count_rech_3g_9', 'av_rech_amt_data_6', 'av_rech_amt_data_7',\n",
       "       'av_rech_amt_data_8', 'av_rech_amt_data_9', 'arpu_3g_6', 'arpu_3g_7',\n",
       "       'arpu_3g_8', 'arpu_3g_9', 'arpu_2g_6', 'arpu_2g_7', 'arpu_2g_8',\n",
       "       'arpu_2g_9', 'night_pck_user_6', 'night_pck_user_7', 'night_pck_user_8',\n",
       "       'night_pck_user_9', 'fb_user_6', 'fb_user_7', 'fb_user_8', 'fb_user_9'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# missing value (above 60%) columns\n",
    "missing_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# divide data for each month as all month have same coloum, to easy to undestand\n",
    "churn_data_jun = data.filter(regex='(_6$|^jun_)')\n",
    "churn_data_jul = data.filter(regex='(_7$|^jul_)')\n",
    "churn_data_aug = data.filter(regex='(_8$|^aug_)')\n",
    "churn_data_sep = data.filter(regex='(_9$|^sep_)') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((55,), (55,), (55,), (55,))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# each mounth have around 55 column\n",
    "churn_data_jun.columns.shape, churn_data_jul.columns.shape, churn_data_aug.columns.shape, churn_data_sep.columns.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['last_date_of_month_6', 'arpu_6', 'onnet_mou_6', 'offnet_mou_6',\n",
       "       'roam_ic_mou_6', 'roam_og_mou_6', 'loc_og_t2t_mou_6',\n",
       "       'loc_og_t2m_mou_6', 'loc_og_t2f_mou_6', 'loc_og_t2c_mou_6',\n",
       "       'loc_og_mou_6', 'std_og_t2t_mou_6', 'std_og_t2m_mou_6',\n",
       "       'std_og_t2f_mou_6', 'std_og_t2c_mou_6', 'std_og_mou_6', 'isd_og_mou_6',\n",
       "       'spl_og_mou_6', 'og_others_6', 'total_og_mou_6', 'loc_ic_t2t_mou_6',\n",
       "       'loc_ic_t2m_mou_6', 'loc_ic_t2f_mou_6', 'loc_ic_mou_6',\n",
       "       'std_ic_t2t_mou_6', 'std_ic_t2m_mou_6', 'std_ic_t2f_mou_6',\n",
       "       'std_ic_t2o_mou_6', 'std_ic_mou_6', 'total_ic_mou_6', 'spl_ic_mou_6',\n",
       "       'isd_ic_mou_6', 'ic_others_6', 'total_rech_num_6', 'total_rech_amt_6',\n",
       "       'max_rech_amt_6', 'date_of_last_rech_6', 'last_day_rch_amt_6',\n",
       "       'date_of_last_rech_data_6', 'total_rech_data_6', 'max_rech_data_6',\n",
       "       'count_rech_2g_6', 'count_rech_3g_6', 'av_rech_amt_data_6',\n",
       "       'vol_2g_mb_6', 'vol_3g_mb_6', 'arpu_3g_6', 'arpu_2g_6',\n",
       "       'night_pck_user_6', 'monthly_2g_6', 'sachet_2g_6', 'monthly_3g_6',\n",
       "       'sachet_3g_6', 'fb_user_6', 'jun_vbc_3g'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# each mounth have around 55 column with following name\n",
    "churn_data_jun.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>last_date_of_month_6</th>\n",
       "      <th>arpu_6</th>\n",
       "      <th>onnet_mou_6</th>\n",
       "      <th>offnet_mou_6</th>\n",
       "      <th>roam_ic_mou_6</th>\n",
       "      <th>roam_og_mou_6</th>\n",
       "      <th>loc_og_t2t_mou_6</th>\n",
       "      <th>loc_og_t2m_mou_6</th>\n",
       "      <th>loc_og_t2f_mou_6</th>\n",
       "      <th>loc_og_t2c_mou_6</th>\n",
       "      <th>...</th>\n",
       "      <th>vol_3g_mb_6</th>\n",
       "      <th>arpu_3g_6</th>\n",
       "      <th>arpu_2g_6</th>\n",
       "      <th>night_pck_user_6</th>\n",
       "      <th>monthly_2g_6</th>\n",
       "      <th>sachet_2g_6</th>\n",
       "      <th>monthly_3g_6</th>\n",
       "      <th>sachet_3g_6</th>\n",
       "      <th>fb_user_6</th>\n",
       "      <th>jun_vbc_3g</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>197.385</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>83.57</td>\n",
       "      <td>212.17</td>\n",
       "      <td>212.17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>101.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>34.047</td>\n",
       "      <td>24.11</td>\n",
       "      <td>15.74</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>23.88</td>\n",
       "      <td>11.51</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>167.690</td>\n",
       "      <td>11.54</td>\n",
       "      <td>143.33</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.19</td>\n",
       "      <td>29.34</td>\n",
       "      <td>24.11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>221.338</td>\n",
       "      <td>99.91</td>\n",
       "      <td>123.31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>73.68</td>\n",
       "      <td>107.43</td>\n",
       "      <td>1.91</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>261.636</td>\n",
       "      <td>50.31</td>\n",
       "      <td>76.96</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>50.31</td>\n",
       "      <td>67.64</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>50.258</td>\n",
       "      <td>50.16</td>\n",
       "      <td>19.28</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>50.16</td>\n",
       "      <td>16.39</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>429.023</td>\n",
       "      <td>71.03</td>\n",
       "      <td>262.73</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>71.03</td>\n",
       "      <td>252.23</td>\n",
       "      <td>10.38</td>\n",
       "      <td>0.11</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>1069.180</td>\n",
       "      <td>57.84</td>\n",
       "      <td>453.43</td>\n",
       "      <td>16.23</td>\n",
       "      <td>23.74</td>\n",
       "      <td>51.39</td>\n",
       "      <td>308.63</td>\n",
       "      <td>62.13</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>378.721</td>\n",
       "      <td>413.69</td>\n",
       "      <td>94.66</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>297.13</td>\n",
       "      <td>80.96</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>122.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>119.518</td>\n",
       "      <td>33.89</td>\n",
       "      <td>63.48</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>33.89</td>\n",
       "      <td>38.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  last_date_of_month_6    arpu_6  onnet_mou_6  offnet_mou_6  roam_ic_mou_6  \\\n",
       "0            6/30/2014   197.385          NaN           NaN            NaN   \n",
       "1            6/30/2014    34.047        24.11         15.74           0.00   \n",
       "2            6/30/2014   167.690        11.54        143.33           0.00   \n",
       "3            6/30/2014   221.338        99.91        123.31           0.00   \n",
       "4            6/30/2014   261.636        50.31         76.96           0.00   \n",
       "5            6/30/2014    50.258        50.16         19.28           0.00   \n",
       "6            6/30/2014   429.023        71.03        262.73           0.00   \n",
       "7            6/30/2014  1069.180        57.84        453.43          16.23   \n",
       "8            6/30/2014   378.721       413.69         94.66           0.00   \n",
       "9            6/30/2014   119.518        33.89         63.48           0.00   \n",
       "\n",
       "   roam_og_mou_6  loc_og_t2t_mou_6  loc_og_t2m_mou_6  loc_og_t2f_mou_6  \\\n",
       "0            NaN               NaN               NaN               NaN   \n",
       "1           0.00             23.88             11.51              0.00   \n",
       "2           0.00              7.19             29.34             24.11   \n",
       "3           0.00             73.68            107.43              1.91   \n",
       "4           0.00             50.31             67.64              0.00   \n",
       "5           0.00             50.16             16.39              0.00   \n",
       "6           0.00             71.03            252.23             10.38   \n",
       "7          23.74             51.39            308.63             62.13   \n",
       "8           0.00            297.13             80.96              0.00   \n",
       "9           0.00             33.89             38.03              0.00   \n",
       "\n",
       "   loc_og_t2c_mou_6     ...      vol_3g_mb_6  arpu_3g_6  arpu_2g_6  \\\n",
       "0               NaN     ...            83.57     212.17     212.17   \n",
       "1              0.00     ...             0.00        NaN        NaN   \n",
       "2              0.00     ...             0.00        NaN        NaN   \n",
       "3              0.00     ...             0.00        NaN        NaN   \n",
       "4              0.00     ...             0.00       0.00       0.00   \n",
       "5              0.00     ...             0.00        NaN        NaN   \n",
       "6              0.11     ...             0.00        NaN        NaN   \n",
       "7              0.00     ...             0.00        NaN        NaN   \n",
       "8              0.00     ...             0.00        NaN        NaN   \n",
       "9              0.00     ...             0.00        NaN        NaN   \n",
       "\n",
       "   night_pck_user_6  monthly_2g_6  sachet_2g_6  monthly_3g_6  sachet_3g_6  \\\n",
       "0               0.0             0            0             1            0   \n",
       "1               NaN             0            0             0            0   \n",
       "2               NaN             0            0             0            0   \n",
       "3               NaN             0            0             0            0   \n",
       "4               0.0             0            1             0            0   \n",
       "5               NaN             0            0             0            0   \n",
       "6               NaN             0            0             0            0   \n",
       "7               NaN             0            0             0            0   \n",
       "8               NaN             0            0             0            0   \n",
       "9               NaN             0            0             0            0   \n",
       "\n",
       "   fb_user_6  jun_vbc_3g  \n",
       "0        1.0      101.20  \n",
       "1        NaN        0.00  \n",
       "2        NaN        4.17  \n",
       "3        NaN        0.00  \n",
       "4        0.0        0.00  \n",
       "5        NaN        0.00  \n",
       "6        NaN        0.00  \n",
       "7        NaN       18.74  \n",
       "8        NaN      122.16  \n",
       "9        NaN        0.00  \n",
       "\n",
       "[10 rows x 55 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see data for jun mounth\n",
    "churn_data_jun.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# treat the lower missing values by replacing 0 \n",
    "data['total_rech_data_6'] = data['total_rech_data_6'].replace(np.nan, 0)\n",
    "data['total_rech_data_7'] = data['total_rech_data_7'].replace(np.nan, 0)\n",
    "data['total_rech_data_8'] = data['total_rech_data_8'].replace(np.nan, 0)\n",
    "data['total_rech_data_9'] = data['total_rech_data_9'].replace(np.nan, 0)\n",
    "data['av_rech_amt_data_6'] = data['av_rech_amt_data_6'].replace(np.nan, 0)\n",
    "data['av_rech_amt_data_7'] = data['av_rech_amt_data_7'].replace(np.nan, 0)\n",
    "data['av_rech_amt_data_8'] = data['av_rech_amt_data_8'].replace(np.nan, 0)\n",
    "data['av_rech_amt_data_9'] = data['av_rech_amt_data_9'].replace(np.nan, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# treat the missing values based on the values in other coloum\n",
    "data['max_rech_data_6'] = data['date_of_last_rech_data_6'].apply(lambda x: 0 if x == np.nan else 1)\n",
    "data['max_rech_data_7'] = data['date_of_last_rech_data_7'].apply(lambda x: 0 if x == np.nan else 1)\n",
    "data['max_rech_data_8'] = data['date_of_last_rech_data_8'].apply(lambda x: 0 if x == np.nan else 1)\n",
    "data['max_rech_data_9'] = data['date_of_last_rech_data_9'].apply(lambda x: 0 if x == np.nan else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#  treat the higher missing values by replacing -1\n",
    "data['night_pck_user_6'] = data['night_pck_user_6'].replace(np.nan, -1)\n",
    "data['night_pck_user_7'] = data['night_pck_user_7'].replace(np.nan, -1)\n",
    "data['night_pck_user_8'] = data['night_pck_user_8'].replace(np.nan, -1)\n",
    "data['night_pck_user_9'] = data['night_pck_user_9'].replace(np.nan, -1)\n",
    "data['fb_user_6'] = data['fb_user_6'].replace(np.nan, -1)\n",
    "data['fb_user_7'] = data['fb_user_7'].replace(np.nan, -1)\n",
    "data['fb_user_8'] = data['fb_user_8'].replace(np.nan, -1)\n",
    "data['fb_user_9'] = data['fb_user_9'].replace(np.nan, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# treat the missing values based on the values in other coloum\n",
    "data['count_rech_2g_6'] = data['date_of_last_rech_data_6'].apply(lambda x: 0 if x == np.nan else 1)\n",
    "data['count_rech_3g_6'] = data['date_of_last_rech_data_6'].apply(lambda x: 0 if x == np.nan else 1)\n",
    "data['count_rech_2g_7'] = data['date_of_last_rech_data_7'].apply(lambda x: 0 if x == np.nan else 1)\n",
    "data['count_rech_3g_7'] = data['date_of_last_rech_data_7'].apply(lambda x: 0 if x == np.nan else 1)\n",
    "data['count_rech_2g_8'] = data['date_of_last_rech_data_8'].apply(lambda x: 0 if x == np.nan else 1)\n",
    "data['count_rech_3g_8'] = data['date_of_last_rech_data_8'].apply(lambda x: 0 if x == np.nan else 1)\n",
    "data['count_rech_2g_9'] = data['date_of_last_rech_data_9'].apply(lambda x: 0 if x == np.nan else 1)\n",
    "data['count_rech_3g_9'] = data['date_of_last_rech_data_9'].apply(lambda x: 0 if x == np.nan else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mobile_number           0.0\n",
       "circle_id               0.0\n",
       "loc_og_t2o_mou          1.0\n",
       "std_og_t2o_mou          1.0\n",
       "loc_ic_t2o_mou          1.0\n",
       "last_date_of_month_6    0.0\n",
       "last_date_of_month_7    1.0\n",
       "last_date_of_month_8    1.0\n",
       "last_date_of_month_9    2.0\n",
       "arpu_6                  0.0\n",
       "arpu_7                  0.0\n",
       "arpu_8                  0.0\n",
       "arpu_9                  0.0\n",
       "onnet_mou_6             4.0\n",
       "onnet_mou_7             4.0\n",
       "onnet_mou_8             5.0\n",
       "onnet_mou_9             8.0\n",
       "offnet_mou_6            4.0\n",
       "offnet_mou_7            4.0\n",
       "offnet_mou_8            5.0\n",
       "offnet_mou_9            8.0\n",
       "roam_ic_mou_6           4.0\n",
       "roam_ic_mou_7           4.0\n",
       "roam_ic_mou_8           5.0\n",
       "roam_ic_mou_9           8.0\n",
       "roam_og_mou_6           4.0\n",
       "roam_og_mou_7           4.0\n",
       "roam_og_mou_8           5.0\n",
       "roam_og_mou_9           8.0\n",
       "loc_og_t2t_mou_6        4.0\n",
       "                       ... \n",
       "night_pck_user_6        0.0\n",
       "night_pck_user_7        0.0\n",
       "night_pck_user_8        0.0\n",
       "night_pck_user_9        0.0\n",
       "monthly_2g_6            0.0\n",
       "monthly_2g_7            0.0\n",
       "monthly_2g_8            0.0\n",
       "monthly_2g_9            0.0\n",
       "sachet_2g_6             0.0\n",
       "sachet_2g_7             0.0\n",
       "sachet_2g_8             0.0\n",
       "sachet_2g_9             0.0\n",
       "monthly_3g_6            0.0\n",
       "monthly_3g_7            0.0\n",
       "monthly_3g_8            0.0\n",
       "monthly_3g_9            0.0\n",
       "sachet_3g_6             0.0\n",
       "sachet_3g_7             0.0\n",
       "sachet_3g_8             0.0\n",
       "sachet_3g_9             0.0\n",
       "fb_user_6               0.0\n",
       "fb_user_7               0.0\n",
       "fb_user_8               0.0\n",
       "fb_user_9               0.0\n",
       "aon                     0.0\n",
       "aug_vbc_3g              0.0\n",
       "jul_vbc_3g              0.0\n",
       "jun_vbc_3g              0.0\n",
       "sep_vbc_3g              0.0\n",
       "average_recharge        0.0\n",
       "Length: 227, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#missing value after above changes\n",
    "round(data.isnull().sum()/len(data.index), 2)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1018,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now no coloum left with large number of missing value \n",
    "missing_row_percentage = 100 * data.T.isnull().sum().sort_values(ascending=False) / data.shape[1]\n",
    "missing_row_percentage[missing_row_percentage > 50].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "missing_columns = data.columns[100*(data.isnull().sum()/len(data.index)) > 60]\n",
    "data = data.drop(missing_columns,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "og_others_9           8.0\n",
       "std_ic_t2o_mou_9      8.0\n",
       "isd_og_mou_9          8.0\n",
       "ic_others_9           8.0\n",
       "std_og_mou_9          8.0\n",
       "roam_og_mou_9         8.0\n",
       "isd_ic_mou_9          8.0\n",
       "spl_ic_mou_9          8.0\n",
       "roam_ic_mou_9         8.0\n",
       "loc_og_mou_9          8.0\n",
       "loc_og_t2m_mou_9      8.0\n",
       "spl_og_mou_9          8.0\n",
       "offnet_mou_9          8.0\n",
       "std_ic_mou_9          8.0\n",
       "std_og_t2c_mou_9      8.0\n",
       "onnet_mou_9           8.0\n",
       "loc_ic_t2f_mou_9      8.0\n",
       "loc_ic_mou_9          8.0\n",
       "std_og_t2t_mou_9      8.0\n",
       "loc_og_t2c_mou_9      8.0\n",
       "loc_ic_t2t_mou_9      8.0\n",
       "loc_ic_t2m_mou_9      8.0\n",
       "std_og_t2m_mou_9      8.0\n",
       "loc_og_t2t_mou_9      8.0\n",
       "loc_og_t2f_mou_9      8.0\n",
       "std_ic_t2t_mou_9      8.0\n",
       "std_ic_t2m_mou_9      8.0\n",
       "std_og_t2f_mou_9      8.0\n",
       "std_ic_t2f_mou_9      8.0\n",
       "std_og_t2f_mou_8      5.0\n",
       "                     ... \n",
       "total_rech_num_8      0.0\n",
       "total_rech_num_7      0.0\n",
       "total_rech_num_6      0.0\n",
       "total_ic_mou_9        0.0\n",
       "total_ic_mou_8        0.0\n",
       "total_ic_mou_7        0.0\n",
       "total_ic_mou_6        0.0\n",
       "sep_vbc_3g            0.0\n",
       "total_og_mou_9        0.0\n",
       "max_rech_amt_9        0.0\n",
       "last_day_rch_amt_6    0.0\n",
       "last_day_rch_amt_7    0.0\n",
       "max_rech_data_9       0.0\n",
       "count_rech_3g_8       0.0\n",
       "count_rech_3g_7       0.0\n",
       "count_rech_3g_6       0.0\n",
       "count_rech_2g_9       0.0\n",
       "count_rech_2g_8       0.0\n",
       "count_rech_2g_7       0.0\n",
       "count_rech_2g_6       0.0\n",
       "max_rech_data_8       0.0\n",
       "last_day_rch_amt_8    0.0\n",
       "max_rech_data_7       0.0\n",
       "max_rech_data_6       0.0\n",
       "total_rech_data_9     0.0\n",
       "total_rech_data_8     0.0\n",
       "total_rech_data_7     0.0\n",
       "total_rech_data_6     0.0\n",
       "last_day_rch_amt_9    0.0\n",
       "mobile_number         0.0\n",
       "Length: 215, dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#missing value after above changes\n",
    "round(data.isnull().sum().sort_values(ascending=False)/len(data.index), 2)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# drop the coloum mobile_number (not a feature) and circle id (with no variance)\n",
    "data.drop(['mobile_number','circle_id'],axis=1,inplace=True)\n",
    "data = data[data.columns.drop(list(data.filter(regex='date')))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99999, 205)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# fill rest of the coloum with meadian values\n",
    "data = data.fillna(data.median()).dropna(axis=1, how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 99999 entries, 0 to 99998\n",
      "Columns: 205 entries, loc_og_t2o_mou to average_recharge\n",
      "dtypes: float64(160), int64(45)\n",
      "memory usage: 156.4 MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "average_recharge      0.0\n",
       "isd_og_mou_6          0.0\n",
       "og_others_8           0.0\n",
       "og_others_7           0.0\n",
       "og_others_6           0.0\n",
       "spl_og_mou_9          0.0\n",
       "spl_og_mou_8          0.0\n",
       "spl_og_mou_7          0.0\n",
       "spl_og_mou_6          0.0\n",
       "isd_og_mou_9          0.0\n",
       "isd_og_mou_8          0.0\n",
       "isd_og_mou_7          0.0\n",
       "std_og_mou_9          0.0\n",
       "total_og_mou_6        0.0\n",
       "std_og_mou_8          0.0\n",
       "std_og_mou_7          0.0\n",
       "std_og_mou_6          0.0\n",
       "std_og_t2c_mou_9      0.0\n",
       "std_og_t2c_mou_8      0.0\n",
       "std_og_t2c_mou_7      0.0\n",
       "std_og_t2c_mou_6      0.0\n",
       "std_og_t2f_mou_9      0.0\n",
       "std_og_t2f_mou_8      0.0\n",
       "std_og_t2f_mou_7      0.0\n",
       "og_others_9           0.0\n",
       "total_og_mou_7        0.0\n",
       "std_ic_t2m_mou_8      0.0\n",
       "loc_ic_t2f_mou_8      0.0\n",
       "std_ic_t2m_mou_6      0.0\n",
       "std_ic_t2t_mou_9      0.0\n",
       "                     ... \n",
       "std_ic_t2o_mou_6      0.0\n",
       "std_ic_t2f_mou_9      0.0\n",
       "std_ic_t2f_mou_8      0.0\n",
       "std_ic_t2f_mou_7      0.0\n",
       "isd_ic_mou_9          0.0\n",
       "ic_others_6           0.0\n",
       "ic_others_7           0.0\n",
       "ic_others_8           0.0\n",
       "total_rech_data_9     0.0\n",
       "total_rech_data_8     0.0\n",
       "total_rech_data_7     0.0\n",
       "total_rech_data_6     0.0\n",
       "last_day_rch_amt_9    0.0\n",
       "last_day_rch_amt_8    0.0\n",
       "last_day_rch_amt_7    0.0\n",
       "last_day_rch_amt_6    0.0\n",
       "max_rech_amt_9        0.0\n",
       "max_rech_amt_8        0.0\n",
       "max_rech_amt_7        0.0\n",
       "max_rech_amt_6        0.0\n",
       "total_rech_amt_9      0.0\n",
       "total_rech_amt_8      0.0\n",
       "total_rech_amt_7      0.0\n",
       "total_rech_amt_6      0.0\n",
       "total_rech_num_9      0.0\n",
       "total_rech_num_8      0.0\n",
       "total_rech_num_7      0.0\n",
       "total_rech_num_6      0.0\n",
       "ic_others_9           0.0\n",
       "loc_og_t2o_mou        0.0\n",
       "Length: 205, dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data after handlling all the missing values\n",
    "round(data.isnull().sum().sort_values(ascending=False)/len(data.index), 2)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Derive new features\n",
    "create new coloum/feature from existing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#calculting total Operator to Operator talk time uages\n",
    "data['t2t_total_6']=data['loc_og_t2t_mou_6']+data['std_og_t2t_mou_6']+data['loc_ic_t2t_mou_6']+data['std_ic_t2t_mou_6']\n",
    "data['t2t_total_7']=data['loc_og_t2t_mou_7']+data['std_og_t2t_mou_7']+data['loc_ic_t2t_mou_7']+data['std_ic_t2t_mou_7']\n",
    "data['t2t_total_8']=data['loc_og_t2t_mou_8']+data['std_og_t2t_mou_8']+data['loc_ic_t2t_mou_8']+data['std_ic_t2t_mou_8']\n",
    "data['t2t_total_9']=data['loc_og_t2t_mou_9']+data['std_og_t2t_mou_9']+data['loc_ic_t2t_mou_9']+data['std_ic_t2t_mou_9']\n",
    "\n",
    "#calculting total Operator to Other talk time uages\n",
    "data['t2m_total_6']=data['loc_og_t2m_mou_6']+data['std_og_t2m_mou_6']+data['loc_ic_t2m_mou_6']+data['std_ic_t2m_mou_6']\n",
    "data['t2m_total_7']=data['loc_og_t2m_mou_7']+data['std_og_t2m_mou_7']+data['loc_ic_t2m_mou_7']+data['std_ic_t2m_mou_7']\n",
    "data['t2m_total_8']=data['loc_og_t2m_mou_8']+data['std_og_t2m_mou_8']+data['loc_ic_t2m_mou_8']+data['std_ic_t2m_mou_8']\n",
    "data['t2m_total_9']=data['loc_og_t2m_mou_9']+data['std_og_t2m_mou_9']+data['loc_ic_t2m_mou_9']+data['std_ic_t2m_mou_9']\n",
    "\n",
    "#calculting total Operator to Fixed line talk time uages\n",
    "data['t2f_total_6']=data['loc_og_t2f_mou_6']+data['std_og_t2f_mou_6']+data['loc_ic_t2f_mou_6']+data['std_ic_t2f_mou_6']\n",
    "data['t2f_total_7']=data['loc_og_t2f_mou_7']+data['std_og_t2f_mou_7']+data['loc_ic_t2f_mou_7']+data['std_ic_t2f_mou_7']\n",
    "data['t2f_total_8']=data['loc_og_t2f_mou_8']+data['std_og_t2f_mou_8']+data['loc_ic_t2f_mou_8']+data['std_ic_t2f_mou_8']\n",
    "data['t2f_total_9']=data['loc_og_t2f_mou_9']+data['std_og_t2f_mou_9']+data['loc_ic_t2f_mou_9']+data['std_ic_t2f_mou_9']\n",
    "\n",
    "#calculting total Operator to own call center talk time uages\n",
    "# this may help to find the customer calling more to call center usually have issues in services\n",
    "data['t2c_total_6']=data['loc_og_t2c_mou_6']+data['std_og_t2c_mou_6']\n",
    "data['t2c_total_7']=data['loc_og_t2c_mou_7']+data['std_og_t2c_mou_7']\n",
    "data['t2c_total_8']=data['loc_og_t2c_mou_8']+data['std_og_t2c_mou_8']\n",
    "data['t2c_total_9']=data['loc_og_t2c_mou_9']+data['std_og_t2c_mou_9']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "data['cust_care_calls_6']=data['t2c_total_6']/data['total_og_mou_6'].apply(lambda x: 0 if x == np.nan else x)\n",
    "data['cust_care_calls_7']=data['t2c_total_7']/data['total_og_mou_7'].apply(lambda x: 0 if x == np.nan else x)\n",
    "data['cust_care_calls_8']=data['t2c_total_8']/data['total_og_mou_8'].apply(lambda x: 0 if x == np.nan else x)\n",
    "data['cust_care_calls_9']=data['t2c_total_9']/data['total_og_mou_9'].apply(lambda x: 0 if x == np.nan else x)\n",
    "'''\n",
    "data['total_vol_6']=data['vol_2g_mb_6']+data['vol_3g_mb_6']\n",
    "data['total_vol_7']=data['vol_2g_mb_7']+data['vol_3g_mb_7']\n",
    "data['total_vol_8']=data['vol_2g_mb_8']+data['vol_3g_mb_8']\n",
    "data['total_vol_9']=data['vol_2g_mb_9']+data['vol_3g_mb_9']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# calculting Change in the usage for a customer from month 6 to month 7 and month 7 to month 8\n",
    "# calculting Change in outgoing minutes of usage\n",
    "data['total_og_mou_diff_7_6'] = data.total_og_mou_7 - data.total_og_mou_6\n",
    "data['total_og_mou_diff_8_7'] = data.total_og_mou_8 - data.total_og_mou_7\n",
    "\n",
    "# calculting Change in incoming minutes of usage\n",
    "data['total_ic_mou_diff_7_6'] = data.total_ic_mou_7 - data.total_ic_mou_6\n",
    "data['total_ic_mou_diff_8_7'] = data.total_ic_mou_8 - data.total_ic_mou_7\n",
    "\n",
    "# calculting Change in number of rechages\n",
    "data['total_rech_num_diff_7_6'] = data.total_rech_num_7 - data.total_rech_num_6\n",
    "data['total_rech_num_diff_8_7'] = data.total_rech_num_8 - data.total_rech_num_7\n",
    "\n",
    "# calculting Change in amount of rechages\n",
    "data['total_rech_amt_diff_7_6'] = data.total_rech_amt_7 - data.total_rech_amt_6\n",
    "data['total_rech_amt_diff_8_7'] = data.total_rech_amt_8 - data.total_rech_amt_7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count       99999.000000\n",
       "mean          325.238792\n",
       "std           370.833466\n",
       "min             0.000000\n",
       "50%           229.000000\n",
       "70%           368.500000\n",
       "90%           698.000000\n",
       "99%          1590.000000\n",
       "99.9%        3037.514000\n",
       "99.9999%    35861.288025\n",
       "max         37762.500000\n",
       "Name: average_recharge, dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TODO Duplicate operation\n",
    "data.average_recharge.describe(percentiles=[0.7,0.9,0.99,0.999,0.999999])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#TODO Duplicate operation\n",
    "data = data[data.average_recharge > 368.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Mark label/tag Churned customers (churn=1, else 0) based on the Month 9\n",
    "data['churn'] = np.where((data['total_ic_mou_9'] + data['total_og_mou_9']+data['total_vol_9']) == 0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Now drop all the Month 9 coloums\n",
    "data = data[data.columns.drop(list(data.filter(like='_9')))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "churn                      0.0\n",
       "loc_ic_t2f_mou_6           0.0\n",
       "loc_ic_t2m_mou_7           0.0\n",
       "loc_ic_t2m_mou_6           0.0\n",
       "loc_ic_t2t_mou_8           0.0\n",
       "loc_ic_t2t_mou_7           0.0\n",
       "loc_ic_t2t_mou_6           0.0\n",
       "total_og_mou_8             0.0\n",
       "total_og_mou_7             0.0\n",
       "total_og_mou_6             0.0\n",
       "og_others_8                0.0\n",
       "og_others_7                0.0\n",
       "og_others_6                0.0\n",
       "spl_og_mou_8               0.0\n",
       "spl_og_mou_7               0.0\n",
       "spl_og_mou_6               0.0\n",
       "isd_og_mou_8               0.0\n",
       "isd_og_mou_7               0.0\n",
       "isd_og_mou_6               0.0\n",
       "std_og_mou_8               0.0\n",
       "std_og_mou_7               0.0\n",
       "loc_ic_t2m_mou_8           0.0\n",
       "loc_ic_t2f_mou_7           0.0\n",
       "total_rech_amt_diff_8_7    0.0\n",
       "loc_ic_t2f_mou_8           0.0\n",
       "total_ic_mou_6             0.0\n",
       "std_ic_mou_8               0.0\n",
       "std_ic_mou_7               0.0\n",
       "std_ic_mou_6               0.0\n",
       "std_ic_t2o_mou_8           0.0\n",
       "                          ... \n",
       "ic_others_8                0.0\n",
       "ic_others_7                0.0\n",
       "ic_others_6                0.0\n",
       "isd_ic_mou_8               0.0\n",
       "isd_ic_mou_7               0.0\n",
       "isd_ic_mou_6               0.0\n",
       "spl_ic_mou_8               0.0\n",
       "total_rech_data_6          0.0\n",
       "total_rech_data_7          0.0\n",
       "total_rech_data_8          0.0\n",
       "av_rech_amt_data_7         0.0\n",
       "night_pck_user_6           0.0\n",
       "vol_3g_mb_8                0.0\n",
       "vol_3g_mb_7                0.0\n",
       "vol_3g_mb_6                0.0\n",
       "vol_2g_mb_8                0.0\n",
       "vol_2g_mb_7                0.0\n",
       "vol_2g_mb_6                0.0\n",
       "av_rech_amt_data_8         0.0\n",
       "av_rech_amt_data_6         0.0\n",
       "max_rech_data_6            0.0\n",
       "count_rech_3g_8            0.0\n",
       "count_rech_3g_7            0.0\n",
       "count_rech_3g_6            0.0\n",
       "count_rech_2g_8            0.0\n",
       "count_rech_2g_7            0.0\n",
       "count_rech_2g_6            0.0\n",
       "max_rech_data_8            0.0\n",
       "max_rech_data_7            0.0\n",
       "loc_og_t2o_mou             0.0\n",
       "Length: 180, dtype: float64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for any missing value at this level\n",
    "round(data.isnull().sum().sort_values(ascending=False)/len(data.index), 2)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29979, 180)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loc_og_t2o_mou                 1\n",
       "std_og_t2c_mou_8               1\n",
       "std_ic_t2o_mou_6               1\n",
       "std_ic_t2o_mou_7               1\n",
       "std_ic_t2o_mou_8               1\n",
       "max_rech_data_6                1\n",
       "max_rech_data_7                1\n",
       "max_rech_data_8                1\n",
       "count_rech_2g_6                1\n",
       "count_rech_2g_7                1\n",
       "count_rech_2g_8                1\n",
       "count_rech_3g_6                1\n",
       "count_rech_3g_7                1\n",
       "count_rech_3g_8                1\n",
       "loc_ic_t2o_mou                 1\n",
       "std_og_t2o_mou                 1\n",
       "std_og_t2c_mou_7               1\n",
       "std_og_t2c_mou_6               1\n",
       "churn                          2\n",
       "night_pck_user_6               3\n",
       "fb_user_6                      3\n",
       "fb_user_7                      3\n",
       "fb_user_8                      3\n",
       "night_pck_user_7               3\n",
       "night_pck_user_8               3\n",
       "monthly_2g_6                   5\n",
       "monthly_2g_7                   6\n",
       "monthly_2g_8                   6\n",
       "monthly_3g_6                  12\n",
       "monthly_3g_8                  12\n",
       "monthly_3g_7                  15\n",
       "sachet_3g_6                   25\n",
       "sachet_3g_7                   27\n",
       "sachet_3g_8                   29\n",
       "sachet_2g_6                   30\n",
       "sachet_2g_7                   34\n",
       "sachet_2g_8                   34\n",
       "total_rech_data_6             37\n",
       "total_rech_data_7             41\n",
       "total_rech_data_8             46\n",
       "spl_ic_mou_6                  78\n",
       "spl_ic_mou_8                  85\n",
       "spl_ic_mou_7                  93\n",
       "total_rech_num_8              96\n",
       "total_rech_num_7             101\n",
       "total_rech_num_6             102\n",
       "total_rech_num_diff_8_7      114\n",
       "og_others_7                  123\n",
       "og_others_8                  133\n",
       "total_rech_num_diff_7_6      136\n",
       "last_day_rch_amt_7           149\n",
       "max_rech_amt_7               151\n",
       "last_day_rch_amt_6           158\n",
       "max_rech_amt_6               170\n",
       "last_day_rch_amt_8           179\n",
       "max_rech_amt_8               182\n",
       "av_rech_amt_data_6           795\n",
       "av_rech_amt_data_8           838\n",
       "og_others_6                  862\n",
       "av_rech_amt_data_7           864\n",
       "isd_og_mou_8                 939\n",
       "isd_og_mou_6                1113\n",
       "isd_og_mou_7                1124\n",
       "ic_others_6                 1227\n",
       "ic_others_8                 1258\n",
       "ic_others_7                 1371\n",
       "std_og_t2f_mou_8            1626\n",
       "t2c_total_6                 1658\n",
       "loc_og_t2c_mou_6            1658\n",
       "std_og_t2f_mou_7            1714\n",
       "t2c_total_8                 1730\n",
       "loc_og_t2c_mou_8            1730\n",
       "loc_og_t2c_mou_7            1749\n",
       "t2c_total_7                 1749\n",
       "std_og_t2f_mou_6            1773\n",
       "std_ic_t2f_mou_8            1941\n",
       "std_ic_t2f_mou_6            2033\n",
       "std_ic_t2f_mou_7            2075\n",
       "sep_vbc_3g                  2169\n",
       "total_rech_amt_6            2241\n",
       "total_rech_amt_7            2265\n",
       "total_rech_amt_8            2299\n",
       "total_rech_amt_diff_8_7     2582\n",
       "total_rech_amt_diff_7_6     2825\n",
       "average_recharge            3024\n",
       "spl_og_mou_6                3053\n",
       "loc_og_t2f_mou_8            3123\n",
       "spl_og_mou_8                3238\n",
       "loc_og_t2f_mou_6            3251\n",
       "loc_og_t2f_mou_7            3266\n",
       "aon                         3321\n",
       "spl_og_mou_7                3399\n",
       "isd_ic_mou_6                3426\n",
       "isd_ic_mou_8                3489\n",
       "isd_ic_mou_7                3635\n",
       "roam_ic_mou_7               3648\n",
       "roam_ic_mou_8               3653\n",
       "roam_ic_mou_6               4337\n",
       "roam_og_mou_8               4381\n",
       "roam_og_mou_7               4430\n",
       "std_ic_t2t_mou_8            4484\n",
       "std_ic_t2t_mou_6            4606\n",
       "loc_ic_t2f_mou_8            4704\n",
       "std_ic_t2t_mou_7            4706\n",
       "loc_ic_t2f_mou_6            4816\n",
       "loc_ic_t2f_mou_7            4896\n",
       "roam_og_mou_6               5173\n",
       "std_ic_t2m_mou_8            6415\n",
       "std_ic_t2m_mou_6            6678\n",
       "std_ic_t2m_mou_7            6746\n",
       "jun_vbc_3g                  6858\n",
       "vol_3g_mb_6                 7039\n",
       "vol_3g_mb_8                 7143\n",
       "aug_vbc_3g                  7284\n",
       "vol_2g_mb_8                 7304\n",
       "jul_vbc_3g                  7312\n",
       "vol_3g_mb_7                 7435\n",
       "vol_2g_mb_6                 7803\n",
       "vol_2g_mb_7                 7808\n",
       "std_ic_mou_8                8030\n",
       "std_ic_mou_6                8388\n",
       "std_ic_mou_7                8541\n",
       "t2f_total_8                 9471\n",
       "loc_ic_t2t_mou_8            9669\n",
       "total_vol_8                 9694\n",
       "t2f_total_6                 9793\n",
       "loc_ic_t2t_mou_6            9869\n",
       "t2f_total_7                 9955\n",
       "loc_ic_t2t_mou_7            9958\n",
       "total_vol_6                10014\n",
       "total_vol_7                10213\n",
       "loc_og_t2t_mou_8           10769\n",
       "loc_og_t2t_mou_6           11149\n",
       "loc_og_t2t_mou_7           11151\n",
       "std_og_t2t_mou_8           11780\n",
       "std_og_t2t_mou_6           12772\n",
       "std_og_t2t_mou_7           12981\n",
       "std_og_t2m_mou_8           13319\n",
       "std_og_t2m_mou_6           14511\n",
       "std_og_t2m_mou_7           14583\n",
       "loc_ic_t2m_mou_8           15588\n",
       "loc_ic_t2m_mou_6           16010\n",
       "loc_ic_t2m_mou_7           16062\n",
       "loc_og_t2m_mou_8           16154\n",
       "loc_og_t2m_mou_6           16738\n",
       "std_og_mou_8               16858\n",
       "loc_og_t2m_mou_7           16865\n",
       "onnet_mou_8                17597\n",
       "std_og_mou_6               18315\n",
       "std_og_mou_7               18433\n",
       "loc_ic_mou_8               18563\n",
       "onnet_mou_6                18805\n",
       "loc_og_mou_8               18871\n",
       "onnet_mou_7                18933\n",
       "loc_ic_mou_7               19021\n",
       "loc_ic_mou_6               19123\n",
       "loc_og_mou_6               19676\n",
       "loc_og_mou_7               19867\n",
       "total_ic_mou_8             20083\n",
       "total_ic_mou_6             20592\n",
       "total_ic_mou_7             20696\n",
       "offnet_mou_8               21500\n",
       "offnet_mou_6               22441\n",
       "offnet_mou_7               22639\n",
       "total_og_mou_8             23624\n",
       "t2t_total_8                23977\n",
       "total_og_mou_6             24587\n",
       "total_og_mou_7             24892\n",
       "t2t_total_6                25115\n",
       "t2t_total_7                25304\n",
       "total_ic_mou_diff_8_7      25897\n",
       "t2m_total_8                26127\n",
       "total_ic_mou_diff_7_6      26159\n",
       "t2m_total_6                27149\n",
       "t2m_total_7                27210\n",
       "total_og_mou_diff_8_7      27692\n",
       "total_og_mou_diff_7_6      28002\n",
       "arpu_8                     28376\n",
       "arpu_7                     29228\n",
       "arpu_6                     29230\n",
       "dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check the Coloum with No varaince (not changing) value i.e. a column with same value all across\n",
    "#TODO Remove coloum with nunique = 1\n",
    "pd.set_option('display.max_rows', None)\n",
    "data.nunique(axis=0).sort_values(ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfb_user_8                      3\\nfb_user_7                      3\\nfb_user_6                      3\\nnight_pck_user_6               3\\nnight_pck_user_7               3\\nnight_pck_user_8               3\\nmonthly_2g_6                   5\\nmonthly_2g_8                   6\\nmonthly_2g_7                   6\\nmonthly_3g_8                  12\\nmonthly_3g_6                  12\\nmonthly_3g_7                  15\\nsachet_3g_6                   25\\nsachet_3g_7                   27\\nsachet_3g_8                   29\\nsachet_2g_6                   30\\nsachet_2g_8                   34\\nsachet_2g_7                   34\\n'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "fb_user_8                      3\n",
    "fb_user_7                      3\n",
    "fb_user_6                      3\n",
    "night_pck_user_6               3\n",
    "night_pck_user_7               3\n",
    "night_pck_user_8               3\n",
    "monthly_2g_6                   5\n",
    "monthly_2g_8                   6\n",
    "monthly_2g_7                   6\n",
    "monthly_3g_8                  12\n",
    "monthly_3g_6                  12\n",
    "monthly_3g_7                  15\n",
    "sachet_3g_6                   25\n",
    "sachet_3g_7                   27\n",
    "sachet_3g_8                   29\n",
    "sachet_2g_6                   30\n",
    "sachet_2g_8                   34\n",
    "sachet_2g_7                   34\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2589, 180)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data.churn == 1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sachet_3g_6\n",
       "0     2450\n",
       "1       87\n",
       "2       16\n",
       "3        8\n",
       "4       11\n",
       "5        1\n",
       "6        3\n",
       "7        4\n",
       "8        1\n",
       "9        2\n",
       "10       4\n",
       "19       1\n",
       "23       1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TODO: Finding the coloum with catagorical values \n",
    "data[data.churn == 1].groupby('sachet_3g_6').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#data[(data.sachet_3g_8 == 0) & (data.churn == 1)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# TODO Finding the coloum with catagorical values  \n",
    "categorical_variables = ['fb_user_8','fb_user_7','fb_user_6','night_pck_user_6','night_pck_user_7','night_pck_user_8','monthly_2g_6','monthly_2g_8','monthly_2g_7','monthly_3g_8','monthly_3g_6','monthly_3g_7','sachet_3g_6','sachet_3g_7','sachet_3g_8','sachet_2g_6','sachet_2g_8','sachet_2g_7']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TODO: the coloum with catagorical values \n",
    "data_cleaned = data.copy()\n",
    "data_cleaned.to_csv('imputed_clean_churn_data.csv')\n",
    "predicted_val = 'churn'\n",
    "for cat_var in categorical_variables:\n",
    "    churn_rate_replace_dict = data_cleaned[[cat_var, predicted_val]].groupby(cat_var).mean().to_dict()[predicted_val]\n",
    "    data[cat_var] =  data[cat_var].replace(churn_rate_replace_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "continuous_variables = list(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "decision_tree_data = data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "continuous_variables.remove('churn')\n",
    "continuous_data = data[continuous_variables]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "churn_frame = data['churn']\n",
    "data = data.drop(['churn'],axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cols = list(continuous_data)\n",
    "nunique = continuous_data.apply(pd.Series.nunique)\n",
    "cols_to_drop = nunique[nunique == 1].index\n",
    "continuous_data = continuous_data.drop(cols_to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "normalized_df=(continuous_data-continuous_data.mean())/continuous_data.std()\n",
    "data = data.drop(continuous_variables, 1)\n",
    "data = pd.concat([data,normalized_df,churn_frame],axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "data_majority = data[data.churn==0]\n",
    "data_minority = data[data.churn==1]\n",
    "\n",
    "df_minority_upsampled = resample(data_minority, replace=True, n_samples=data[data.churn == 0].shape[0], random_state=123)\n",
    "data = pd.concat([df_minority_upsampled, data_majority])\n",
    "data = data.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## 4. Splitting the Test and Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Putting feature variable to X\n",
    "X = data.drop(['churn'],axis=1)\n",
    "\n",
    "# Putting response variable to y\n",
    "y = data['churn']\n",
    "# Splitting the data into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, train_size=0.7,test_size=0.3,random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train.shape,X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. PCA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Improting the PCA module\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(svd_solver='randomized', random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "null_columns=data.columns[data.isnull().any()]\n",
    "data[null_columns].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Doing the PCA on the train data\n",
    "pca.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pca.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "colnames = list(X_train.columns)\n",
    "pcs_df = pd.DataFrame({'PC1':pca.components_[0],'PC2':pca.components_[1], 'Feature':colnames})\n",
    "pcs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "fig = plt.figure(figsize = (8,8))\n",
    "plt.scatter(pcs_df.PC1, pcs_df.PC2)\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "for i, txt in enumerate(pcs_df.Feature):\n",
    "    plt.annotate(txt, (pcs_df.PC1[i],pcs_df.PC2[i]))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Making the screeplot - plotting the cumulative variance against the number of components\n",
    "%matplotlib inline\n",
    "fig = plt.figure(figsize = (12,8))\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('number of components')\n",
    "plt.ylabel('cumulative explained variance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Using incremental PCA for efficiency - saves a lot of time on larger datasets\n",
    "from sklearn.decomposition import IncrementalPCA\n",
    "pca_final = IncrementalPCA(n_components=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_train_pca = pca_final.fit_transform(X_train)\n",
    "df_train_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#creating correlation matrix for the principal components\n",
    "corrmat = np.corrcoef(df_train_pca.transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#plotting the correlation matrix\n",
    "%matplotlib inline\n",
    "plt.figure(figsize = (20,10))\n",
    "sns.heatmap(corrmat,annot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 1s -> 0s in diagonals\n",
    "corrmat_nodiag = corrmat - np.diagflat(corrmat.diagonal())\n",
    "print(\"max corr:\",corrmat_nodiag.max(), \", min corr: \", corrmat_nodiag.min(),)\n",
    "# we see that correlations are indeed very close to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Applying selected components to the test data - 16 components\n",
    "df_test_pca = pca_final.transform(X_test)\n",
    "df_test_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Training the model on the train data\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "\n",
    "learner_pca_logistic = LogisticRegression()\n",
    "model_pca_logistic = learner_pca_logistic.fit(df_train_pca,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Making prediction on the test data\n",
    "pred_probs_test = model_pca_logistic.predict_proba(df_test_pca)[:,1]\n",
    "\"{:2.2}\".format(metrics.roc_auc_score(y_test, pred_probs_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 6. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pca_again = PCA(0.90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_train_pca2 = pca_again.fit_transform(X_train)\n",
    "df_train_pca2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#training the regression model\n",
    "learner_pca2_logistic = LogisticRegression()\n",
    "model_pca2_logistic = learner_pca2_logistic.fit(df_train_pca2,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_test_pca2 = pca_again.transform(X_test)\n",
    "df_test_pca2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Making prediction on the test data\n",
    "pred_probs_test2 = model_pca2_logistic.predict_proba(df_test_pca2)[:,1]\n",
    "\"{:2.2f}\".format(metrics.roc_auc_score(y_test, pred_probs_test2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import validation_curve\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "svm_model = SVC(kernel='linear', class_weight='balanced', C=1.0, random_state=123) \n",
    "svm_pca_model = svm_model.fit(df_train_pca2,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_test_pca2 = pca_again.transform(X_test)\n",
    "df_test_pca2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred_probs_test2 = svm_pca_model.predict(df_test_pca2)\n",
    "\"{:2.2f}\".format(metrics.roc_auc_score(y_test, pred_probs_test2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "svm_model = SVC(kernel='linear', class_weight='balanced', C=1.0, random_state=123) \n",
    "svm_original_model = svm_model.fit(X_train,y_train)\n",
    "pred_probs_test_original = svm_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"{:2.2f}\".format(metrics.roc_auc_score(y_test, pred_probs_test_original))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Putting feature variable to X\n",
    "X = decision_tree_data.drop(['churn'],axis=1)\n",
    "\n",
    "# Putting response variable to y\n",
    "y = decision_tree_data['churn']\n",
    "# Splitting the data into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, train_size=0.7,test_size=0.3,random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Importing decision tree classifier from sklearn library\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Fitting the decision tree with default hyperparameters, apart from\n",
    "# max_depth which is 5 so that we can plot and read the tree.\n",
    "dt_default = DecisionTreeClassifier(max_depth=5)\n",
    "dt_default.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Let's check the evaluation metrics of our default model\n",
    "\n",
    "# Importing classification report and confusion matrix from sklearn metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# Making predictions\n",
    "y_pred_default = dt_default.predict(X_test)\n",
    "\n",
    "# Printing classification report\n",
    "print(classification_report(y_test, y_pred_default))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Printing confusion matrix and accuracy\n",
    "print(confusion_matrix(y_test,y_pred_default))\n",
    "print(accuracy_score(y_test,y_pred_default))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Importing required packages for visualization\n",
    "from IPython.display import Image  \n",
    "from sklearn.externals.six import StringIO  \n",
    "from sklearn.tree import export_graphviz\n",
    "import pydot, graphviz\n",
    "\n",
    "# Putting features\n",
    "features = list(decision_tree_data.columns[:-1])\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plotting tree with max_depth=3\n",
    "dot_data = StringIO()  \n",
    "export_graphviz(dt_default, out_file=dot_data,\n",
    "                feature_names=features, filled=True,rounded=True)\n",
    "\n",
    "graph = pydot.graph_from_dot_data(dot_data.getvalue())  \n",
    "Image(graph[0].create_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# GridSearchCV to find optimal max_depth\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "# specify number of folds for k-fold CV\n",
    "n_folds = 5\n",
    "\n",
    "# parameters to build the model on\n",
    "parameters = {'max_depth': range(1, 40)}\n",
    "\n",
    "# instantiate the model\n",
    "dtree = DecisionTreeClassifier(criterion = \"gini\", \n",
    "                               random_state = 100)\n",
    "\n",
    "# fit tree on training data\n",
    "tree = GridSearchCV(dtree, parameters, \n",
    "                    cv=n_folds, \n",
    "                   scoring=\"accuracy\")\n",
    "tree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# scores of GridSearch CV\n",
    "scores = tree.cv_results_\n",
    "pd.DataFrame(scores).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plotting accuracies with max_depth\n",
    "plt.figure()\n",
    "plt.plot(scores[\"param_max_depth\"], \n",
    "         scores[\"mean_train_score\"], \n",
    "         label=\"training accuracy\")\n",
    "plt.plot(scores[\"param_max_depth\"], \n",
    "         scores[\"mean_test_score\"], \n",
    "         label=\"test accuracy\")\n",
    "plt.xlabel(\"max_depth\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# GridSearchCV to find optimal max_depth\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "# specify number of folds for k-fold CV\n",
    "n_folds = 5\n",
    "\n",
    "# parameters to build the model on\n",
    "parameters = {'min_samples_leaf': range(5, 200, 20)}\n",
    "\n",
    "# instantiate the model\n",
    "dtree = DecisionTreeClassifier(criterion = \"gini\", \n",
    "                               random_state = 100)\n",
    "\n",
    "# fit tree on training data\n",
    "tree = GridSearchCV(dtree, parameters, \n",
    "                    cv=n_folds, \n",
    "                   scoring=\"accuracy\")\n",
    "tree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# scores of GridSearch CV\n",
    "scores = tree.cv_results_\n",
    "pd.DataFrame(scores).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plotting accuracies with min_samples_leaf\n",
    "plt.figure()\n",
    "plt.plot(scores[\"param_min_samples_leaf\"], \n",
    "         scores[\"mean_train_score\"], \n",
    "         label=\"training accuracy\")\n",
    "plt.plot(scores[\"param_min_samples_leaf\"], \n",
    "         scores[\"mean_test_score\"], \n",
    "         label=\"test accuracy\")\n",
    "plt.xlabel(\"min_samples_leaf\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# GridSearchCV to find optimal min_samples_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "# specify number of folds for k-fold CV\n",
    "n_folds = 5\n",
    "\n",
    "# parameters to build the model on\n",
    "parameters = {'min_samples_split': range(5, 200, 20)}\n",
    "\n",
    "# instantiate the model\n",
    "dtree = DecisionTreeClassifier(criterion = \"gini\", \n",
    "                               random_state = 100)\n",
    "\n",
    "# fit tree on training data\n",
    "tree = GridSearchCV(dtree, parameters, \n",
    "                    cv=n_folds, \n",
    "                   scoring=\"accuracy\")\n",
    "tree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# scores of GridSearch CV\n",
    "scores = tree.cv_results_\n",
    "pd.DataFrame(scores).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plotting accuracies with min_samples_leaf\n",
    "plt.figure()\n",
    "plt.plot(scores[\"param_min_samples_split\"], \n",
    "         scores[\"mean_train_score\"], \n",
    "         label=\"training accuracy\")\n",
    "plt.plot(scores[\"param_min_samples_split\"], \n",
    "         scores[\"mean_test_score\"], \n",
    "         label=\"test accuracy\")\n",
    "plt.xlabel(\"min_samples_split\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create the parameter grid \n",
    "param_grid = {\n",
    "    'max_depth': range(5, 15, 5),\n",
    "    'min_samples_leaf': range(50, 150, 50),\n",
    "    'min_samples_split': range(50, 150, 50),\n",
    "    'criterion': [\"entropy\", \"gini\"]\n",
    "}\n",
    "\n",
    "n_folds = 5\n",
    "\n",
    "# Instantiate the grid search model\n",
    "dtree = DecisionTreeClassifier()\n",
    "grid_search = GridSearchCV(estimator = dtree, param_grid = param_grid, \n",
    "                          cv = n_folds, verbose = 1)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# cv results\n",
    "cv_results = pd.DataFrame(grid_search.cv_results_)\n",
    "cv_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# printing the optimal accuracy score and hyperparameters\n",
    "print(\"best accuracy\", grid_search.best_score_)\n",
    "print(grid_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model with optimal hyperparameters\n",
    "clf_gini = DecisionTreeClassifier(criterion = \"gini\", \n",
    "                                  random_state = 100,\n",
    "                                  max_depth=10, \n",
    "                                  min_samples_leaf=50,\n",
    "                                  min_samples_split=50)\n",
    "clf_gini.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# accuracy score\n",
    "clf_gini.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plotting the tree\n",
    "dot_data = StringIO()  \n",
    "export_graphviz(clf_gini, out_file=dot_data,feature_names=features,filled=True,rounded=True)\n",
    "\n",
    "graph = pydot.graph_from_dot_data(dot_data.getvalue())  \n",
    "Image(graph[0].create_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# tree with max_depth = 3\n",
    "clf_gini = DecisionTreeClassifier(criterion = \"gini\", \n",
    "                                  random_state = 100,\n",
    "                                  max_depth=3, \n",
    "                                  min_samples_leaf=50,\n",
    "                                  min_samples_split=50)\n",
    "clf_gini.fit(X_train, y_train)\n",
    "\n",
    "# score\n",
    "print(clf_gini.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plotting tree with max_depth=3\n",
    "dot_data = StringIO()  \n",
    "export_graphviz(clf_gini, out_file=dot_data,feature_names=features,filled=True,rounded=True)\n",
    "\n",
    "graph = pydot.graph_from_dot_data(dot_data.getvalue())  \n",
    "Image(graph[0].create_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# classification metrics\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "y_pred = clf_gini.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "print(confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 8. XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from xgboost import plot_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "churn_data = pd.read_csv('imputed_clean_churn_data.csv')\n",
    "# Putting feature variable to X\n",
    "X = churn_data.drop(['churn'],axis=1)\n",
    "\n",
    "# Putting response variable to y\n",
    "y = churn_data['churn']\n",
    "# Splitting the data into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, train_size=0.7,test_size=0.3,random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = XGBClassifier(scale_pos_weight=0.5 )\n",
    "model.fit(X_train, y_train)\n",
    "# plot single tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.figure(figsize=(50,50))\n",
    "plot_tree(model)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict_proba(X_test)\n",
    "y_pred[:10]\n",
    "roc = metrics.roc_auc_score(y_test, y_pred[:, 1])\n",
    "print(\"AUC: %.2f%%\" % (roc * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "# specify number of folds for k-fold CV\n",
    "n_folds = 5\n",
    "\n",
    "# parameters to build the model on\n",
    "parameters = {'max_depth': range(1, 40),\n",
    "             'learning_rate': np.arange(0.0, 1.0, 0.01),\n",
    "             'gamma': np.arange(0.0, 3.0, 0.1)}\n",
    "\n",
    "# instantiate the model\n",
    "xgboost = XGBClassifier(scale_pos_weight=0.5, random_state=40)\n",
    "\n",
    "# fit tree on training data\n",
    "xgboost = GridSearchCV(xgboost, parameters, \n",
    "                    cv=n_folds, \n",
    "                   scoring=\"accuracy\")\n",
    "xgboost.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores = xgboost.cv_results_\n",
    "pd.DataFrame(scores).head()\n",
    "# plotting accuracies with max_depth\n",
    "plt.figure()\n",
    "plt.plot(scores[\"param_max_depth\"], \n",
    "         scores[\"mean_train_score\"], \n",
    "         label=\"training accuracy\")\n",
    "plt.plot(scores[\"param_max_depth\"], \n",
    "         scores[\"mean_test_score\"], \n",
    "         label=\"test accuracy\")\n",
    "plt.xlabel(\"max_depth\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(scores[\"param_learning_rate\"], \n",
    "         scores[\"mean_train_score\"], \n",
    "         label=\"training accuracy\")\n",
    "plt.plot(scores[\"param_learning_rate\"], \n",
    "         scores[\"mean_test_score\"], \n",
    "         label=\"test accuracy\")\n",
    "plt.xlabel(\"Learning Rate\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(scores[\"param_gamma\"], \n",
    "         scores[\"mean_train_score\"], \n",
    "         label=\"training accuracy\")\n",
    "plt.plot(scores[\"param_gamma\"], \n",
    "         scores[\"mean_test_score\"], \n",
    "         label=\"test accuracy\")\n",
    "plt.xlabel(\"Gamma\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
